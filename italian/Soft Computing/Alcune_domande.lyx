#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\use_hyperref false
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Soft Computing 
\end_layout

\begin_layout Part
2014 Febbrario 07
\end_layout

\begin_layout Section
Feedforward Neural Networks
\end_layout

\begin_layout Standard
Consider the classical feed forward neural network architecture with I input
 neurons, J hidden neurons and 1 output neuron:
\end_layout

\begin_layout Itemize
Draw it and write the output characteristics got the output [1 point]
\end_layout

\begin_deeper
\begin_layout Standard
Nel disegnarla ricordare che ogne neurone dello strato di input è collegati
 con ogni neurone dello strato dell'hidden layer.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
y=g\left(\sum_{j}^{J}W_{j}h\left(\sum_{i}^{i}w_{i}x_{i}\right)\right)
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
Define the general formula for the weights update according to backpropagation
 (i.e.
 gradient descent) [1 point]
\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset Formula 
\[
w\left(t\right)=w\left(t-1\right)+\Delta w
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
w\left(t\right)=w\left(t-1\right)-\eta\frac{\partial E}{\partial w}
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
Derive the error function of weight decay starting from the Maximum A-Posteriori
 principle to weight estimation [1 point]
\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset Formula 
\[
\hat{w}=\arg\max_{w}\prod_{n}^{N}\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{1}{2\sigma^{2}}\left(t_{n}-y_{n}\right)^{2}}\prod_{m}^{M}\frac{1}{\sqrt{2\pi}\sigma_{w}}e^{-\frac{1}{2\sigma_{w}^{2}}\left(-w_{m}\right)^{2}}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\hat{w}=\arg\min_{w}\sum_{n}^{N}\frac{1}{2\sigma^{2}}\left(t_{n}-y_{n}\right)^{2}+\sum_{m}^{M}\frac{1}{2\sigma_{m}^{2}}\left(w_{m}\right)^{2}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\gamma=\frac{\sigma^{2}}{\sigma_{w}^{2}}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\hat{w}=\arg\min_{w}\sum_{n}^{N}\left(t_{n}-y_{n}\right)^{2}+\gamma\sum_{m}^{M}w_{m}^{2}
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
Derive the 2 backpropagation formulas, respectively for the weight going
 into the output neuron and into the hidden neurons, using the weight dacay
 error function [2 points]
\end_layout

\begin_deeper
\begin_layout Itemize
For the output neuron
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\hat{w}^{t+1}=w^{t}-\eta\frac{\partial E}{\partial w}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=w^{t}-\eta\frac{\partial}{\partial w}\left(\sum_{n}^{N}\left(t_{n}-g\left(A\right)\right)^{2}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
A=W_{j}b_{j}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{\partial E}{\partial w_{j}}=\sum_{n}^{N}2\left(t-g\left(A\right)\right)\cdot\frac{\partial}{\partial W_{j}}\left(t-g\left(A\right)\right)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\sum_{n}^{N}2\left(t-g\left(A\right)\right)\cdot\left(-g'\left(A\right)\right)\cdot\frac{\partial}{\partial W_{j}}A
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\sum_{n}^{N}2\left(t-g\left(A\right)\right)\cdot\left(-g'\left(A\right)\right)\cdot b_{j}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
W_{j}^{t+1}=W_{j}^{t}+2\eta\sum_{n}^{N}\left(t-g\left(A\right)\right)\cdot\left(g'\left(A\right)\right)\cdot b_{j}
\]

\end_inset


\end_layout

\begin_layout Itemize
For the hidden neurons
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{\partial E}{\partial w_{j,i}}=\sum_{n}^{N}2\left(t-g\left(A\right)\right)\cdot\left(-g'\left(A\right)\right)\cdot\frac{\partial}{\partial w_{j,i}}A
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\sum_{n}^{N}2\left(t-g\left(A\right)\right)\cdot\left(-g'\left(A\right)\right)\cdot W_{j}\cdot\frac{\partial}{\partial w_{j,i}}b_{j}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\sum_{n}^{N}2\left(t-g\left(A\right)\right)\cdot\left(-g'\left(A\right)\right)\cdot W_{j}\cdot h'\left(a_{j}\right)\cdot\frac{\partial}{\partial w_{j,i}}a_{j}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
w_{j,i}^{t+1}=w_{j,i}^{t}+2\eta\sum_{n}^{N}\left(t-g\left(A\right)\right)\cdot g'\left(A\right)\cdot W_{j}\cdot h'\left(a_{j}\right)\cdot x_{i}
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
Describe the issue of overfitting and describe, in details, the early stopping
 technique to avoid it [2 points]
\end_layout

\begin_deeper
\begin_layout Itemize
Overfitting is when the model learn the data noise and does not generalize
 on new samples (it memorize the training set).
 It can happen also when the number of training examples is too small to
 produce a representative sample of the true target function.
\end_layout

\begin_layout Itemize
Early stopping technique consist in stopping the learning process before
 it starts to fit the noise in the data.
 It it useful to split the data in two sets, one for the learning process
 and one for the test process.
 A good point to stop the algorithm is when the error measured on the test
 set starts to increase.
 It is also useful to decide how many neurons put in the hidden layer.
\end_layout

\end_deeper
\begin_layout Itemize
How could we estimate the 
\begin_inset Formula $\gamma$
\end_inset

 in the weight decay formula? [1 point]
\end_layout

\begin_deeper
\begin_layout Itemize
We can chose 
\begin_inset Formula $\gamma$
\end_inset

 to minimize the error function over 
\begin_inset Formula $\gamma$
\end_inset

.
\end_layout

\end_deeper
\begin_layout Section
Bayesian Network
\end_layout

\begin_layout Itemize
Ho conditional independency is defined?
\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $a$
\end_inset

 e 
\begin_inset Formula $b$
\end_inset

 sono condizionatamente indipendenti dato 
\begin_inset Formula $c$
\end_inset

 se 
\begin_inset Formula $p\left(a|b,c\right)=p\left(a|c\right)$
\end_inset

.
\end_layout

\end_deeper
\begin_layout Itemize
What is the difference between Monte Carlo sampling and likelihood weighting?
 When should we prefer Monte Carlo sampling w.r.t.
 likelihood sampling? When should we prefer likelihood sampling w.r.t.
 Monte Carlo sampling? 
\end_layout

\begin_deeper
\begin_layout Itemize
Monte Carlo sampling è utile perché non richiede conoscenze preliminari
 sulla rete se non le probabilità condizionate.
 Genera molti campioni, non tutti vengono però utilizzati per calcolare
 la probabilità richiesta.
\end_layout

\begin_layout Itemize
Likelihood sampling necessita di calcolare per ogni campione la probabilità
 di essere generato ed è quindi più oneroso computazionalmente.
 Ha il vantaggio di generare solamente campioni utili ai fini del calcolo
 della probabilità richiesta, fissando i valori delle variabili date (genera
 campioni solo sulle probabilità non note).
 A parità di campioni generati è molto più preciso del Monte Carlo sampling.
\end_layout

\begin_layout Itemize
Qualora non fosse possibile conoscere le probabilità condizionate della
 rete è necessario utilizzare Monte Carlo sampling, in tutti gli altri casi
 è preferibile likelihood sampling.
\end_layout

\end_deeper
\begin_layout Part
2005 Luglio 08
\end_layout

\begin_layout Section
Fuzzy
\end_layout

\begin_layout Itemize
Come può essere implementato il modicatore fuzzy "very"? [3 punti]
\end_layout

\begin_deeper
\begin_layout Standard
Si eleva al quadrato il valore restituito dalla membership function.
\end_layout

\end_deeper
\begin_layout Section
Radial Basis Function
\end_layout

\begin_layout Itemize
In cosa si dierenzia dalle classiche topoligie feed-forward questa topologia?
 [2 punti]
\end_layout

\begin_deeper
\begin_layout Itemize
In both cases the mappings are expressed in terms of parametrized compositions
 of functions of single variables.
 The particular structures of the two networks are very different, however.
\end_layout

\begin_layout Itemize
The hidden unit representations of the multi-layer perceptron depend on
 weighted linear summations of the inputs, transformed by monotonic activation
 functions.
 By contrast, the hidden units in a radial basis function network use distance
 to a prototype vector followed by transformation with a (usually) localized
 function.
\end_layout

\begin_layout Itemize
A multi-layer perceptron can be said to form a distributed representation
 in the space of activation values for the hidden units since, for a given
 input vector, many hidden units will typically contribute to the determination
 of the output value.
 By contrast, a radial basis function network with localized basis functions
 forms a representation in the space of hidden units which is local with
 respect to the input space because, for a given input vector, typically
 only a few hidden units will have significant activations.
\end_layout

\begin_layout Itemize
A multi-layer perceptron often has many layers of weights, and a complex
 pattern of connectivity, so that not all possible weights in any given
 layer are present.
 Also, a variety of different activation functions may be used within the
 same network.
 A radial basis function network, however, generally has a simple architecture
 consisting of two layers of weights, in which the first layer contains
 the parameters of the basis functions, and the second layer forms linear
 combinations of the activations of the basis functions to generate the
 outputs.
\end_layout

\begin_layout Itemize
All of the parameters in a multi-layer perceptron are usually determined
 at the same time as part of a single global training strategy involving
 supervised training.
 A radial basis function network, however, is typically trained in two stages,
 with the basis functions being determined first by unsupervised techniques
 using the input data alone, and the secondlayer weights subsequently being
 found by fast linear supervised methods.
\end_layout

\end_deeper
\begin_layout Itemize
È possibile che si verifichino problemi di overfitting con questo tipo di
 reti? Nel caso affermativo, se ne faccia un esempio, altrimenti se ne spieghi
 il motivo [2 punti].
\end_layout

\begin_deeper
\begin_layout Itemize
Si, dipende dalla kernel function.
 Se allochiamo una funzione gaussiana per ogni campione 
\begin_inset Formula $\left\langle x_{n},f\left(x_{n}\right)\right\rangle ~N\left(x_{n},\sigma{}^{2}\right)$
\end_inset

, avremo comunque problemi di overfitting dato che la funzione registra
 anche il rumore dei dati.
 Una possibile soluzione alternativa per la scelta dei kernel che garantisce
 capacità di generalizzazione migliori consiste in una U relativamente piccola,
 aggiungere un neurone alla volta, allenare la rete e inserire un nuovo
 neurone in corrispondenza del record col più alto errore di predizione.
\end_layout

\end_deeper
\begin_layout Section
Algoritmi Genetici
\end_layout

\begin_layout Itemize
Riportare lo schema generale di un algoritmo genetico [3 punti]
\end_layout

\begin_deeper
\begin_layout Enumerate
[Start] Generate random population of n chromosomes (suitable solutions)
\end_layout

\begin_layout Enumerate
[Fitness] Evaluate the fitness f(x) of each chromosome x in the population
\end_layout

\begin_layout Enumerate
[New population] Create a new population by repeating the following steps
 until the new population is complete
\end_layout

\begin_deeper
\begin_layout Enumerate
[Selection] Select two parent chromosomes from a population according to
 their fitness (the better fitness, the bigger chance to be selected)
\end_layout

\begin_layout Enumerate
[Crossover] With a crossover probability cross over the parents to form
 new offspring.
 If no crossover was performed, offspring is the exact copy of parents.
\end_layout

\begin_layout Enumerate
[Mutation] With a mutation probability mutate new offsprings at each locus
\end_layout

\begin_layout Enumerate
[Accepting] Place new offsprings in the new population
\end_layout

\end_deeper
\begin_layout Enumerate
[Replace] Use new generated population for a further run of the algorithm
\end_layout

\begin_layout Enumerate
[Test] If the end condition is satisfied, return the best solution in current
 population
\end_layout

\begin_layout Enumerate
[Loop] Go to step 2
\end_layout

\end_deeper
\begin_layout Part
2008 Febbraio 20
\end_layout

\begin_layout Section
Radial Basis Function
\end_layout

\begin_layout Itemize
Si disegni una RBF con 3 ingressi e 2 uscite, si riporti quindi la formulazione
 matematica dell’output di tale RBF
\end_layout

\begin_deeper
\begin_layout Standard
Supponendo di usare una funzione gaussiana come Kernel, ovvero 
\begin_inset Formula $K_{u}\left(d\left(x_{u},x\right)\right)=e^{-\frac{1}{2\sigma^{2}}d^{2}\left(x_{u},x\right)}$
\end_inset

 si ha:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
y=w_{0}+\sum_{u=1}^{U}w_{u}\cdot e^{-\frac{1}{2\sigma^{2}}d^{2}\left(x_{u},x\right)}
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
E possibile applicare un algoritmo di backpropagation al modello RBF? Se
 si perché non lo si fa e cosa si applica nella pratica?
\end_layout

\begin_deeper
\begin_layout Standard
Non si usa il backpropagation perché viene di solito usato per addestrare
 reti con pesi diversi per ogni funzione di attivazione.
 Le RBF invece vengono addestrate in un processo a due passaggi:
\end_layout

\begin_layout Enumerate
The number U of hidden units is determined and each hidden unit is defined
 by choosing the values of 
\begin_inset Formula $x_{u}$
\end_inset

 and 
\begin_inset Formula $\sigma_{u}^{2}$
\end_inset

 that define its kernel function 
\begin_inset Formula $K_{u}\left(d\left(x_{u},x\right)\right)$
\end_inset

.
\end_layout

\begin_layout Enumerate
The weights 
\begin_inset Formula $w_{u}$
\end_inset

 are trained to maximize the fitting of the network using the error function;
 Since the kernel functions are held fixed during the second stage, the
 linear weights 
\begin_inset Formula $w_{u}$
\end_inset

 can be trained very efficiently.
\end_layout

\end_deeper
\begin_layout Part
2005 Giugno 27
\end_layout

\begin_layout Section
Fuzzy
\end_layout

\begin_layout Itemize
Quanto vale la somma dei due numeri fuzzy triangolari (0,2,4) e (2,4,8)?
\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset Formula $\left[0+2,\,2+4,\,4+8\right]=\left[2,\,6,\,12\right]$
\end_inset


\end_layout

\end_deeper
\begin_layout Part
Altre cacate
\end_layout

\begin_layout Standard
Derive the 2 backpropagation formulas for the error function 
\begin_inset Formula $E=\sum_{n}^{N}t_{n}\log y_{n}+\left(1-t_{n}\right)\log\left(1-y_{n}\right)$
\end_inset


\end_layout

\begin_layout Itemize
first formula
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{\partial E}{\partial W_{j}}=\sum_{n}^{N}\frac{t_{n}}{y_{n}}\cdot g'\left(A\right)\cdot\frac{\partial A}{\partial W_{j}}+\frac{1-t_{n}}{1-y_{n}}\cdot\left(-g'\left(A\right)\right)\cdot\frac{\partial A}{\partial W_{j}}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
A=W_{j}\cdot b_{j}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{\partial E}{\partial W_{j}}=\sum_{n}^{N}\frac{t_{n}}{y_{n}}\cdot g'\left(A\right)\cdot b_{j}-\frac{1-t_{n}}{1-y_{n}}\cdot g'\left(A\right)\cdot b_{j}
\]

\end_inset


\end_layout

\begin_layout Itemize
second formula
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{\partial E}{\partial w_{j,i}}=\sum_{n}^{N}\frac{t_{n}}{y_{n}}\cdot g'\left(A\right)\cdot\frac{\partial A}{\partial w_{j,i}}+\frac{1-t_{n}}{1-y_{n}}\cdot\left(-g'\left(A\right)\right)\cdot\frac{\partial A}{\partial w_{j,i}}
\]

\end_inset

 
\begin_inset Formula 
\[
b_{j}=h\left(\sum_{i}^{I}a_{j,i}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
a_{j,i}=w_{j,i}\cdot x_{i}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{\partial E}{\partial w_{j,i}}=\sum_{n}^{N}\frac{t_{n}}{y_{n}}\cdot g'\left(A\right)\cdot W_{j}\cdot h'\left(a_{j}\right)\cdot x_{i}-\frac{1-t_{n}}{1-y_{n}}\cdot g'\left(A\right)\cdot W_{j}\cdot h'\left(a_{j}\right)\cdot x_{i}
\]

\end_inset


\end_layout

\end_body
\end_document
