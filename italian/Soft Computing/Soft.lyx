#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\begin_preamble
\usepackage{url}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language italian
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\float_placement h
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_title "Soft Computing"
\pdf_subject "Neural Networks"
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks true
\pdf_pdfborder true
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Neural Networks
\end_layout

\begin_layout Author
Stefano Cherubin
\end_layout

\begin_layout Abstract
Tentativo di riassumere e chiarificare i concetti della sezione 
\emph on
Neural Networks
\emph default
 del corso 
\emph on
Soft Computing
\emph default
.
 Di questo documento non viene fornita garanzia di esattezza, completezza,
 utilità.
\end_layout

\begin_layout Standard
\begin_inset Newpage clearpage
\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Section
Miximum Likelihood Estimation
\end_layout

\begin_layout Standard
Dato un insieme di campioni 
\begin_inset Formula $\theta$
\end_inset

 che sappiamo essere provenienti da un certo tipo di distribuzione, ad esempio
 una gaussiana di varianza nota, calcoliamo la probabilità che i campioni
 appartengano ad una distribuzione generica di quel tipo, ad esempio una
 gaussiana di media incognita.
 
\end_layout

\begin_layout Standard
Tale funzione si dice funzione di likelihood, il parametro (o i parametri)
 che la massimizza determina il modello da adottare.
\end_layout

\begin_layout Subsection
Procedimento
\end_layout

\begin_layout Enumerate
Scrivere likelihood function 
\begin_inset Formula $L=P\left(Data|\theta\right)$
\end_inset


\end_layout

\begin_layout Enumerate
Calcolarne il logaritmo 
\begin_inset Formula $\mathcal{L}=\log P\left(Data|\theta\right)$
\end_inset


\end_layout

\begin_layout Enumerate
Derivare 
\begin_inset Formula $\frac{\partial L}{\partial\theta}$
\end_inset

 o 
\begin_inset Formula $\frac{\partial\mathcal{L}}{\partial\theta}$
\end_inset


\end_layout

\begin_layout Enumerate
Risolvere il sistema di equazioni 
\begin_inset Formula $\frac{\partial\mathcal{L}}{\partial\theta_{i}}=0$
\end_inset


\end_layout

\begin_layout Enumerate
Verificare l'esattezza della soluzione, ovvero che 
\begin_inset Formula $\theta^{mle}$
\end_inset

 massimizza 
\begin_inset Formula $L$
\end_inset

.
\end_layout

\begin_layout Subsection
Gaussiana univariata
\end_layout

\begin_layout Enumerate
\begin_inset Formula $L\left(\mu\right)=\prod_{n=1}^{N}\frac{1}{\sqrt{2\pi\sigma^{2}}}e^{-\frac{\left(x_{n}-\mu\right)^{2}}{2\sigma^{2}}}$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\mathcal{L}=N\left(\log\frac{1}{\sqrt{2\pi\sigma^{2}}}\right)-\frac{1}{2\sigma^{2}}\sum_{n=1}^{N}\left(x_{n}-\mu\right)^{2}$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\frac{\partial\mathcal{L}}{\partial\mu}=\frac{1}{2\sigma^{2}}\sum_{n=1}^{N}2\left(x_{n}-\mu\right)$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\sum_{n=1}^{N}\left(x_{n}-\mu\right)=0$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\mu^{mle}=\frac{1}{N}\sum_{n=1}^{N}x_{n}
\]

\end_inset


\end_layout

\begin_layout Subsection
Metodi numerici: Discesa del gradiente
\end_layout

\begin_layout Enumerate
Prendere random una possibile soluzione 
\begin_inset Formula $k_{0}$
\end_inset


\end_layout

\begin_layout Enumerate
Calcolarne la derivata 
\begin_inset Formula $\frac{\partial E\left(k\right)}{\partial k}|_{k_{n}}$
\end_inset


\end_layout

\begin_layout Enumerate
Aggiornare la soluzione 
\begin_inset Formula $k_{n}=k_{n-1}-\gamma\cdot\frac{\partial E\left(k\right)}{\partial k}|_{k_{n-1}}$
\end_inset


\end_layout

\begin_layout Enumerate
Ripetere i passi 2 e 3 fino a convergenza
\end_layout

\begin_layout Subsubsection
Possibili problemi e possibili soluzioni
\end_layout

\begin_layout Standard
Problemi:
\end_layout

\begin_layout Itemize
Diversi minimi locali.
\end_layout

\begin_layout Itemize
Lenta convergenza.
\end_layout

\begin_layout Itemize
Nessuna convergenza.
\end_layout

\begin_layout Standard
Soluzioni:
\end_layout

\begin_layout Itemize
Multiple inizializzazioni random.
\end_layout

\begin_layout Itemize
Usare derivate seconde.
\end_layout

\begin_layout Itemize
Ridurre 
\begin_inset Formula $\gamma$
\end_inset

.
\end_layout

\begin_layout Section
Neural Networks
\end_layout

\begin_layout Subsection
Introduzione
\end_layout

\begin_layout Subsubsection
Perché
\end_layout

\begin_layout Standard
Caratteristiche di un modello di rete neuronale
\end_layout

\begin_layout Itemize
Gestisce bene dati soggetti a 
\series bold
rumore
\series default
 (intrinseco o ambientale).
\end_layout

\begin_layout Itemize
Fortemente 
\series bold
parallelo
\series default
.
\end_layout

\begin_layout Itemize

\series bold
Ridondante
\series default
, resistente ai guasti.
\end_layout

\begin_layout Itemize
Si 
\series bold
adatta
\series default
 bene a variazioni ambientali.
\end_layout

\begin_layout Standard
Approccio diverso dal paradigma di Von Neumann.
\end_layout

\begin_layout Subsubsection
Utilizzi
\end_layout

\begin_layout Itemize
Modellazione (regressione)
\end_layout

\begin_layout Itemize
Classificazione
\end_layout

\begin_layout Subsubsection
Nota Linguistica
\end_layout

\begin_layout Description
Rete
\begin_inset space ~
\end_inset

Neurale 
\emph on
Neural Network
\emph default
.
 Rete di neuroni (biologia).
\end_layout

\begin_layout Description
Rete
\begin_inset space ~
\end_inset

Neuronale 
\emph on
Artificiale Neural Network
\emph default
.
 Rete di neuroni artificiali (machine learning).
\end_layout

\begin_layout Subsection
Neurone: dalla biologia al machine learning
\end_layout

\begin_layout Standard
Un neurone accumula carica dai recettori attraverso le sinapsi.
 Possono esserci sinapsi eccitatorie o inibitorie, con pesi variabili.
 Quando questa carica supera una certa soglia, il neurone scarica attraverso
 l'assone.
 
\end_layout

\begin_layout Subsubsection
Neurone artificiale
\end_layout

\begin_layout Standard
\align center
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename img/ArtificialNeuronModel_english.png
	lyxscale 40
	scale 15

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption

\begin_layout Plain Layout
Neurone artificiale
\begin_inset CommandInset citation
LatexCommand cite
key "neurone_artificiale"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Un generico neurone 
\begin_inset Formula $j$
\end_inset

 è descritto da:
\end_layout

\begin_layout Itemize
pesi delle sinapsi 
\begin_inset Formula $w_{j,i}$
\end_inset


\end_layout

\begin_layout Itemize
valore di attivazione 
\begin_inset Formula $net_{j}=\sum_{i}w_{j,i}x_{i}$
\end_inset


\end_layout

\begin_layout Itemize
soglia di attivazione 
\begin_inset Formula $\theta_{j}=-w_{j,0}\cdot1$
\end_inset


\end_layout

\begin_layout Itemize
funzione di attivazione 
\begin_inset Formula $\varphi=g_{j}\left(\right)$
\end_inset


\end_layout

\begin_layout Standard
L'output del neurone è definito come
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
o_{j}=g\left(-\theta_{j}+\sum_{i=1}^{N}w_{j,i}x_{i}\right)=g\left(\sum_{i=0}^{N}w_{j,i}x_{i}\right)
\]

\end_inset


\end_layout

\begin_layout Subsubsection
Comuni funzioni di attivazione
\end_layout

\begin_layout Description
Scalino limitata tra 
\begin_inset Formula $-1$
\end_inset

 e 
\begin_inset Formula $+1$
\end_inset

 con discontinuità di terzo tipo in 
\begin_inset Formula $\left(0,0\right)$
\end_inset

.
\end_layout

\begin_layout Description
Lineare una retta passante per l'origine di arbitrario coefficiente angolare.
\end_layout

\begin_layout Description
Sigmoide limitata tra 
\begin_inset Formula $0$
\end_inset

 e 
\begin_inset Formula $+1$
\end_inset

 sempre derivabile.
\end_layout

\begin_layout Description
Tangente
\begin_inset space ~
\end_inset

iperbolica limitata tra 
\begin_inset Formula $-1$
\end_inset

 e 
\begin_inset Formula $+1$
\end_inset

 sempre derivabile.
\end_layout

\begin_layout Subsection
Percettrone
\end_layout

\begin_layout Standard
È il primo, nonchè il più semplice modello di neurone artificiale.
\end_layout

\begin_layout Itemize
Singolo strato
\end_layout

\begin_layout Itemize
Modellizza bene le porte logiche
\end_layout

\begin_deeper
\begin_layout Itemize
bisezione del piano di input tramite una retta
\end_layout

\end_deeper
\begin_layout Itemize
Non modellizza lo 
\series bold
XOR
\series default
!
\end_layout

\begin_layout Subsection
Hebbian Learning
\end_layout

\begin_layout Subsubsection
Regola di Hebb
\end_layout

\begin_layout Standard
Hebb Learning Rule (1949)
\end_layout

\begin_layout Quotation
La forza di una sinapsi aumenta in accordo con la simultanea attivazione
 dell'input relativo e dell'obiettivo desiderato.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
w_{i}^{n+1}=w^{n}+\Delta w_{i}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\Delta w_{i}=\eta\cdot t\cdot x_{i}
\]

\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $\eta$
\end_inset

: learning rate;
\end_layout

\begin_layout Itemize
\begin_inset Formula $x_{i}$
\end_inset

 è l'i-esimo input del percettrone;
\end_layout

\begin_layout Itemize
\begin_inset Formula $t$
\end_inset

: output desiderato (target).
\end_layout

\begin_layout Standard
In parole povere, dice che se due neuroni si attivano contemporaneamente,
 la loro interconnessione deve essere rafforzata.
\end_layout

\begin_layout Subsubsection
Procedimento di apprendimento
\end_layout

\begin_layout Enumerate
Fissare un tasso di apprendimento 
\begin_inset Formula $\eta$
\end_inset

 arbitrario.
\end_layout

\begin_layout Enumerate
Inizializzare con valori random tutti i pesi 
\begin_inset Formula $w_{i}$
\end_inset

.
\end_layout

\begin_layout Enumerate
Evolvere un'epoca come segue:
\end_layout

\begin_deeper
\begin_layout Enumerate
data una serie di input, calcolare l'output.
\end_layout

\begin_layout Enumerate
aggiornare i pesi secondo la regola di Hebb.
\end_layout

\begin_layout Enumerate
ripetere per tutti i possibili input.
\end_layout

\begin_deeper
\begin_layout Enumerate
termine dell'epoca.
\end_layout

\end_deeper
\end_deeper
\begin_layout Enumerate
Se tutti i 
\begin_inset Formula $\Delta w_{i}$
\end_inset

 erano nulli l'algoritmo è terminato altrimenti ripetere dal punto precedente.
\end_layout

\begin_layout Standard
Da notare che più il tasso di apprendimento 
\begin_inset Formula $\eta$
\end_inset

 è elevato, più facilmente varierà il valore associato al peso 
\begin_inset Formula $w_{i}^{n+1}$
\end_inset

.
\end_layout

\begin_layout Subsection
Topologia FeedForward
\end_layout

\begin_layout Standard
Le reti FeedForward sono reti in cui il flusso dei dati scorre dall'input
 attraverso lo strato nascosto verso l'output senza mai tornare indietro
 o formare cicli.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename img/MultiLayerNeuralNetworkBigger_english.png
	lyxscale 50
	scale 28

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Neural Network FeedForward
\begin_inset CommandInset citation
LatexCommand cite
key "NeuralNetwork_FeedForward"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Possono essere reti a singolo strato o, più comunemente, multistrato.
\end_layout

\begin_layout Subsubsection
Percettrone multistrato
\end_layout

\begin_layout Standard
Risolve il problema dello XOR.
\end_layout

\begin_layout Standard
Oltre a input e output, introduce livelli nascosti di percettroni.
 Questo consente di avere valori intermedi su cui basare l'output.
 A patto di aumentare il numero di percettroni per livello, è sufficiente
 un unico livello nascosto di percettroni per avere l'espressività necessaria
 a modellizzare qualunque rete neuronale con 
\begin_inset Formula $N$
\end_inset

 livelli nascosti.
\end_layout

\begin_layout Description
Layer insieme di neuroni a uguale distanza dagli input.
\end_layout

\begin_layout Description
Input
\begin_inset space ~
\end_inset

Layer layer di neuroni che riceve come input i dati da processare.
\end_layout

\begin_layout Description
Output
\begin_inset space ~
\end_inset

Layer layer di neuroni che forniscono l'output.
\end_layout

\begin_layout Subsubsection
Modello di una rete neuronale
\end_layout

\begin_layout Standard
È non lineare ed è caratterizzato da:
\end_layout

\begin_layout Itemize
numero di neuroni
\end_layout

\begin_layout Itemize
topologia
\end_layout

\begin_layout Itemize
funzioni di attivazione 
\begin_inset Formula $h\left(\right)\quad g\left(\right)$
\end_inset


\end_layout

\begin_layout Itemize
pesi delle sinapsi
\end_layout

\begin_layout Itemize
soglie di attivazione
\end_layout

\begin_layout Subsubsection
Apprendimento in un percettrone multistrato
\end_layout

\begin_layout Standard
Si utilizza la tecnica di discesa del gradiente per minimizzare una funzione
 di errore.
 Tecnica altrimenti nota con i nomi:
\end_layout

\begin_layout Itemize
Delta rule
\end_layout

\begin_layout Itemize
Widrow Hoff rule
\end_layout

\begin_layout Itemize
Adaline rule
\end_layout

\begin_layout Itemize
Backpropagation
\end_layout

\begin_layout Standard
La cui formula si può esprimere come 
\begin_inset Formula 
\[
w^{n+1}=w^{n}+\Delta w
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\Delta w=-\eta\cdot\frac{\partial E}{\partial w}
\]

\end_inset


\end_layout

\begin_layout Standard
Dove
\begin_inset Formula ${\displaystyle \frac{\partial E}{\partial w}}$
\end_inset

è il gradiente della funzione d'errore rispetto ai pesi.
\end_layout

\begin_layout Subsubsection
Esempio backpropagation
\end_layout

\begin_layout Standard
L'obiettivo è approssimare una funzione 
\begin_inset Formula $t$
\end_inset

 dato un insieme di N osservazioni
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
y=g\left(\sum_{j}^{J}W_{j}\cdot h\left(\sum_{i}^{I}w_{j,i}x_{i}\right)\right)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
E=\sum_{n}^{N}\left(t_{n}-y_{n}\right)^{2}
\]

\end_inset


\end_layout

\begin_layout Standard
L'errore in pratica è dato dalla sommatoria del quadrato della differenza
 tra il valore che la funzione t restituisce e quello che restituisce la
 mia approssimazione.
\end_layout

\begin_layout Description
Valore
\begin_inset space ~
\end_inset

di
\begin_inset space ~
\end_inset

attivazione 
\begin_inset Formula $a_{j}=\sum_{i}^{I}w_{j,i}x_{i}$
\end_inset


\end_layout

\begin_layout Description
Output
\begin_inset space ~
\end_inset

del
\begin_inset space ~
\end_inset

j-esimo
\begin_inset space ~
\end_inset

neurone 
\begin_inset Formula $b_{j}=h\left(a_{j}\right)$
\end_inset


\end_layout

\begin_layout Description
Funzione
\begin_inset space ~
\end_inset

di
\begin_inset space ~
\end_inset

errore 
\begin_inset Formula $E$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
A=\sum_{j}^{J}W_{j}b_{j}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $E=\sum_{n}^{N}\left(t_{n}-y_{n}\right)^{2}=\sum_{n}^{N}\left(t_{n}-g\left(A\right)\right)^{2}$
\end_inset


\end_layout

\begin_layout Standard
Dove 
\begin_inset Formula $g(A)$
\end_inset

 è la funzione di attivazione che prende in ingresso le uscite dei neuroni
 dello strato intermedio per i relativi pesi.
\end_layout

\begin_layout Standard
\begin_inset Formula $\frac{\partial E}{\partial W_{j}}=\sum_{n}^{N}2\left(t-g\left(A\right)\right)\cdot\left(-g'\left(A\right)\right)\cdot\frac{\partial A}{\partial W_{j}}=\sum_{n}^{N}2\left(t-g\left(A\right)\right)\cdot\left(-g'\left(A\right)\right)\cdot b_{j}$
\end_inset


\end_layout

\begin_layout Standard
Andando a sostituire il risultato nella formula della backpropagation, si
 ottiene la regola di 
\emph on
backpropagation update
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
W_{j}^{t+1}=W_{j}^{t}+2\eta\sum_{n}^{N}\left(t-g\left(A\right)\right)\cdot g'\left(A\right)\cdot b_{j}
\]

\end_inset


\end_layout

\begin_layout Standard
Questi calcoli mostrano come approssimare per iterazioni successive i pesi
 per il neurone dello strato d'uscita.
 Altrettanto è possibile fare per i neuroni dello strato nascosto, aggiornando
 i pesi attribuiti agli ingressi.
 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
w_{j,i}^{t+1}=w_{j,i}^{t}+2\eta\sum_{n}^{N}\left(t-g\left(A\right)\right)\cdot g'\left(A\right)\cdot W_{j}\cdot h'(a_{j})\cdot x_{i}
\]

\end_inset


\end_layout

\begin_layout Subsubsection
Regressione
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
t_{n}=y_{n}+\epsilon_{n}\quad\epsilon\sim N\left(0,\sigma^{2}\right)\;\rightarrow\; t_{n}\sim N\left(y_{n},\sigma^{2}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
L'obiettivo diventa quindi approssimare una funzione obiettivo 
\begin_inset Formula $t_{n}$
\end_inset

 dato un insieme finito di 
\begin_inset Formula $N$
\end_inset

 campioni osservati.
 Si suppone che i campioni siano indipendenti ed identicamente distribuiti
 e che la distribuzione dell'errore nelle osservazioni sia normale di varianza
 
\begin_inset Formula $\sigma^{2}$
\end_inset

.
 Applichiamo allora la Maximum Likelihood Estimation (MLE) per approssimare
 
\begin_inset Formula $t_{n}$
\end_inset

.
\end_layout

\begin_layout Standard
Otteniamo la funzione di verosimiglianza
\begin_inset Formula 
\[
L\left(w\right)=\prod_{n}^{N}\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{\left(t_{n}-y_{n}\right)^{2}}{2\sigma^{2}}}
\]

\end_inset


\end_layout

\begin_layout Standard
Cerchiamo i pesi che massimizzano questa funzione.
 Per farlo passiamo dalla log verosimiglianza perché il logaritmo è una
 funzione monotona e che preserva il massimo (e ci semplifica alcuni calcoli)
 
\begin_inset Formula 
\[
\arg\max_{w}L\left(w\right)=\arg\max_{w}\log L\left(w\right)=\arg\min_{w}\sum_{n}^{N}\left(t_{n}-y_{n}\right)^{2}
\]

\end_inset


\end_layout

\begin_layout Standard
Tutto ciò che non dipende da 
\begin_inset Formula $w$
\end_inset

, si elimina! Ed è per questo che:
\end_layout

\begin_layout Standard
\begin_inset Formula $\arg\max_{w}\log L\left(w\right)=\arg\max_{w}-\sum_{n}^{N}[log(\frac{1}{\sigma\sqrt{2\pi}})-\frac{\left(t_{n}-y_{n}\right)^{2}}{2\sigma^{2}}]$
\end_inset


\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\lang english
\begin_inset Formula $=\arg\max_{w}-\sum_{n}^{N}\frac{\left(t_{n}-y_{n}\right)^{2}}{2\sigma^{2}}$
\end_inset


\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\lang english
\begin_inset Formula $=\arg\min_{w}\sum_{n}^{N}\left(t_{n}-y_{n}\right)^{2}$
\end_inset


\end_layout

\begin_layout Subsubsection
Classificazione
\end_layout

\begin_layout Standard
L'obiettivo qui è di separare diverse classi di elementi 
\begin_inset Formula $\Omega_{0}$
\end_inset

, 
\begin_inset Formula $\Omega_{1}$
\end_inset

, ..., 
\begin_inset Formula $\Omega_{n}$
\end_inset

.
 Prendiamo come esempio una classificazione binaria, con funzione obiettivo
 
\begin_inset Formula $t$
\end_inset

 descritta come di seguito
\end_layout

\begin_layout Standard
\begin_inset Formula $\begin{array}{cc}
t\in\Omega_{0} & 0\\
t\notin\Omega_{0}\Longleftrightarrow t\in\Omega_{1} & 1
\end{array}$
\end_inset


\end_layout

\begin_layout Standard
La distribuzione di probabilità da adottare è una bernoulliana 
\begin_inset Formula $p\left(t|x\right)=y^{t}\left(1-y\right)^{1-t}$
\end_inset

.
\end_layout

\begin_layout Standard
Come prima, otteniamo la funzione di verosimiglianza
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
L\left(w\right)=\prod_{n}^{N}y_{n}^{t_{n}}\left(1-y_{n}\right)^{1-t_{n}}
\]

\end_inset


\end_layout

\begin_layout Standard
e massimizzandola i calcoli sono...
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\arg\max_{w}L\left(w\right)=\arg\min_{w}-\sum_{n}^{N}\left[t_{n}\log y_{n}+\left(1-t_{n}\right)\log\left(1-y_{n}\right)\right]
\]

\end_inset


\end_layout

\begin_layout Subsection
Problemi e soluzioni
\end_layout

\begin_layout Subsubsection
Miglioramento della convergenza
\end_layout

\begin_layout Itemize
Discesa del gradiente con momento
\end_layout

\begin_deeper
\begin_layout Itemize
Agisce applicando un filtro passa-basso per saltare i minimi locali.
\end_layout

\end_deeper
\begin_layout Itemize
Metodi 
\emph on
quasi Newton
\end_layout

\begin_deeper
\begin_layout Itemize
Trova il punto con derivata seconda nulla assumendo che la funzione sia
 approssimabile a quadratica nel punto di minimo.
\end_layout

\end_deeper
\begin_layout Itemize
Metodi del gradiente coniugato
\end_layout

\begin_deeper
\begin_layout Itemize
Non utilizza la massima pendenza come nella discesa del gradiente.
 Si basa su una matrice di pesi applicati a superfici di livello.
\end_layout

\end_deeper
\begin_layout Subsubsection
Subottimi (o ottimi locali)
\end_layout

\begin_layout Itemize
Multiple restarts
\end_layout

\begin_deeper
\begin_layout Itemize
esegue molteplici volte l'algoritmo con diversi punti di inizio.
 Riduce possibilità di cadere in ottimi locali.
\end_layout

\end_deeper
\begin_layout Itemize
Metodi randomizzati
\end_layout

\begin_layout Subsubsection
Generalizzazione ed overfitting
\end_layout

\begin_layout Itemize
Weight decay
\end_layout

\begin_layout Itemize
Early stopping
\end_layout

\begin_layout Subsection
Generalizzazione e Overfitting
\end_layout

\begin_layout Description
Overfitting si ha overfitting quando il modello appreso asseconda anche
 il rumore intrinseco del campione di dati e quindi perde di generalizzazione
 e non ci si può aspettare di applicarlo ad un nuovo campione di dati e
 ottenere risultati simili.
\end_layout

\begin_layout Subsubsection
Misurare il livello di generalizzazione di un modello
\end_layout

\begin_layout Enumerate
Costruire il modello senza un sottoinsieme di dati (test set).
\end_layout

\begin_layout Enumerate
Usare i dati del test set per la valutazione.
\end_layout

\begin_layout Subsubsection
Evitare overfitting
\end_layout

\begin_layout Itemize
Tecniche di cross validazione.
\end_layout

\begin_layout Itemize
Includere una distorsione statistica nel modello per controbilanciare il
 rumore.
\end_layout

\begin_layout Paragraph
Early stopping
\end_layout

\begin_layout Standard
Questa tecnica consiste nell'interrompere il processo di apprendimento tramite
 ottimizzazione per fasi.
 L'interruzione deve avvenire quando le performance sul test set iniziano
 a peggiorare anche se sul training set.
\end_layout

\begin_layout Paragraph
Weight decay
\end_layout

\begin_layout Standard
Introduce un termine che penalizza la complessità della rete.
\end_layout

\begin_layout Standard
La tecnica di MLE finora usata prevedeva
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\hat{w}=\arg\max_{w}P\left(D|w\right)
\]

\end_inset


\end_layout

\begin_layout Standard
Usando invece una tecnica 
\series bold
Maximum A-Posteriori
\series default
 su un 
\emph on
approccio Bayesiano
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\hat{w}=\arg\max_{w}P\left(w|D\right)=\arg\max P\left(D|w\right)P\left(w\right)
\]

\end_inset


\end_layout

\begin_layout Standard
...necessitiamo quindi di conoscere preventivamente la distribuzione dei pesi
 
\begin_inset Formula $P\left(w\right)$
\end_inset

.
\end_layout

\begin_layout Itemize
Migliorare generalizzazione usando pesi piccoli 
\begin_inset Formula $w\sim N\left(0,\sigma_{w}^{2}\right)$
\end_inset

.
\end_layout

\begin_layout Itemize
Usare distribuzioni iniziali coniugate per avere i valori a posteriori più
 comodi.
\end_layout

\begin_layout Standard
Vediamo un po' di formule
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\hat{w}=\arg\max_{w}\prod_{n}^{N}\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{\left(t_{n}-y_{n}\right)^{2}}{2\sigma^{2}}}\cdot\prod_{m}^{M}\frac{1}{\sqrt{2\pi}\sigma_{w}}e^{-\frac{\left(0-w_{m}\right)^{2}}{2\sigma_{w}^{2}}}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\hat{w}=\arg\min_{w}\sum_{n}^{N}\left(t_{n}-y\right)^{2}+\gamma\sum_{m}^{M}w^{2}
\]

\end_inset


\end_layout

\begin_layout Subsection
Radial basis function network
\end_layout

\begin_layout Subsubsection
Definizione
\end_layout

\begin_layout Standard
Una radial basis function network è una rete neuronale che fa uso di funzioni
 a base radiale come funzioni di attivazione.
 L'output di una rete di questo tipo è una combinazione lineare di funzioni
 (a base radiale) degli input della rete e parametri dei neuroni.
\begin_inset Formula 
\[
y=\varphi\left(x,param\right)=\sum_{u}^{U}\alpha_{u}\cdot\rho\left(\left|\left|x-c_{u}\right|\right|\right)
\]

\end_inset


\end_layout

\begin_layout Subsubsection
Approssimazione a base radiale
\end_layout

\begin_layout Standard
Dati un insieme finito di punti, campionati da una 
\begin_inset Formula $f(x)$
\end_inset

, si vuole ottenere un'approssimazione di tale funzione utilizzando una
 rete formata da 
\begin_inset Formula $U$
\end_inset

 percettroni.
 Ognuno di questi percettroni rappresenta una funzione di base 
\begin_inset Formula $K_{u}$
\end_inset

 che dipende dalla distanza euclidea tra il centro 
\begin_inset Formula $x_{u}$
\end_inset

 (riferimento per il percettrone 
\begin_inset Formula $u$
\end_inset

) ed il vettore di ingressi 
\begin_inset Formula $x$
\end_inset

.
 La funzione di approssimazione può essere espressa come
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\hat{f}(x)=w_{o}+\overset{U}{\underset{u=1}{\sum}}w_{u}\cdot K_{u}\left(d\left(x_{u},x\right)\right)
\]

\end_inset


\end_layout

\begin_layout Standard
dove:
\end_layout

\begin_layout Itemize
\begin_inset Formula $x$
\end_inset

 è un vettore di input;
\end_layout

\begin_layout Itemize
\begin_inset Formula $K_{u}\left(d\left(x_{u},x\right)\right)$
\end_inset

 è chiamata kernel function ed è definita in modo tale da decrescere al
 crescere della distanza euclidea 
\begin_inset Formula $d\left(x_{u},x\right)$
\end_inset

.
\end_layout

\begin_layout Standard
Fissato un valore 
\begin_inset Formula $U$
\end_inset

 sufficientemente elevato di funzioni a base radiale è possibile approssimare
 una qualsiasi funzione con la distanza euclidea mantenendo un errore relativame
nte piccolo.
\end_layout

\begin_layout Standard
Il valore di attivazione 
\begin_inset Formula $z_{j}$
\end_inset

 di un generico neurone della rete, può essere espresso come prodotto scalare
 (prodotto elemento per elemento fra corrispondenti) tra il vettore di ingressi
 
\begin_inset Formula $x$
\end_inset

 ed il vettore trasposto dei pesi delle sinapsi in ingresso al percettrone
 
\begin_inset Formula $j$
\end_inset

 (i pesi dell’unità j-esima nascosta) 
\begin_inset Formula $w_{j}^{T}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
z_{j}=\overset{N}{\underset{i=1}{\sum}}w_{j,i}\cdot x_{i}=\overset{N}{\underset{i=1}{\sum}}x_{i}\cdot w_{j,i}=x\cdot w_{j}^{T}
\]

\end_inset


\end_layout

\begin_layout Standard
Rinominando l’indice 
\begin_inset Formula $j$
\end_inset

 (il pedice dei pesi 
\begin_inset Formula $w$
\end_inset

) con la lettera 
\begin_inset Formula $u$
\end_inset

 (perché consideriamo 
\begin_inset Formula $U$
\end_inset

 percettroni) ed il vettore 
\begin_inset Formula $w$
\end_inset

 di pesi con il vettore 
\begin_inset Formula $x$
\end_inset

 dei centri dei percettroni
\end_layout

\begin_layout Itemize
\begin_inset Formula $w_{j}^{T}\Longrightarrow x_{u}^{T}$
\end_inset


\end_layout

\begin_layout Standard
si ottiene che le distanze tra i centri dei percettroni e gli ingressi possono
 essere espresse tramite prodotto scalare dei due vettori 
\begin_inset Formula $x$
\end_inset

 e 
\begin_inset Formula $x_{u}^{T}$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
d\left(x_{u},x\right)=x\cdot x_{u}^{T}
\]

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
\begin_inset Formula $d\left(x_{u},x\right)=z_{u}???$
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Manca sezione RBF learning
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage clearpage
\end_inset


\end_layout

\begin_layout Section
Bibliografia
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "bib/ArtificialNeuronModel_english,bib/NeuralNetwork_FeedForward"
options "plain"

\end_inset


\end_layout

\end_body
\end_document
